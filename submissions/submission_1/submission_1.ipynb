{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dC_e1pit81L"
      },
      "outputs": [],
      "source": [
        "!pip install paddlepaddle paddleocr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "from joblib import Parallel, delayed\n",
        "from paddleocr import PaddleOCR\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Define the dataset path (CSV file)\n",
        "dataset_path = '/content/train.csv'\n",
        "\n",
        "# Define the output CSV file path with extracted text\n",
        "output_csv = '/content/train_with_text.csv'\n",
        "\n",
        "# Define counters for successful extractions and errors\n",
        "success_count = 0\n",
        "error_count = 0\n",
        "\n",
        "# Define the current time\n",
        "start_time = time.time()\n",
        "\n",
        "# Function to upscale the image\n",
        "def upscale_image(image, scale_factor=2):\n",
        "    \"\"\"\n",
        "    Upscales an image by the given scale factor.\n",
        "    \"\"\"\n",
        "    width = int(image.shape[1] * scale_factor)\n",
        "    height = int(image.shape[0] * scale_factor)\n",
        "    dimensions = (width, height)\n",
        "\n",
        "    # Resize the image to the new dimensions\n",
        "    upscaled_image = cv2.resize(image, dimensions, interpolation=cv2.INTER_CUBIC)\n",
        "    return upscaled_image\n",
        "\n",
        "# Function to download image from URL and convert it to an OpenCV image\n",
        "def download_image_from_url(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Raise an exception for failed requests\n",
        "        image = Image.open(BytesIO(response.content)).convert('RGB')  # Convert to RGB\n",
        "        return np.array(image)  # Convert the PIL image to a NumPy array (OpenCV format)\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading image {url}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Define a function for text extraction using PaddleOCR\n",
        "def extract_text(image_path, scale_factor=2):\n",
        "    try:\n",
        "        # Initialize PaddleOCR within the function to avoid PicklingError\n",
        "        ocr = PaddleOCR(use_angle_cls=True, lang='en')\n",
        "\n",
        "        # Check if image_path is a URL (starts with 'http' or 'https')\n",
        "        if image_path.startswith('http'):\n",
        "            # Download the image from the URL\n",
        "            image_cv = download_image_from_url(image_path)\n",
        "        else:\n",
        "            # Load the image from a local file\n",
        "            image_cv = cv2.imread(image_path)\n",
        "\n",
        "        if image_cv is None:\n",
        "            raise ValueError(\"Image could not be loaded, possibly corrupted or invalid format.\")\n",
        "\n",
        "        # Upscale the image to enhance text extraction\n",
        "        image_upscaled = upscale_image(image_cv, scale_factor=scale_factor)\n",
        "\n",
        "        # Convert the image from BGR to RGB (PaddleOCR expects RGB format)\n",
        "        image_rgb = cv2.cvtColor(image_upscaled, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Extract text using PaddleOCR\n",
        "        results = ocr.ocr(image_rgb)  # Returns a list of text boxes and text\n",
        "\n",
        "        # Join the results into a single string\n",
        "        text = '\\n'.join([res[1][0] for res in results[0]])  # Extract text part\n",
        "\n",
        "        return text\n",
        "\n",
        "    except Exception as e:\n",
        "        # Handle exceptions (e.g., if the image is corrupted)\n",
        "        print(f\"Error processing {image_path}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Read the dataset into a pandas DataFrame\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "# Limit the DataFrame to the first 50 rows\n",
        "df = df.head(30)\n",
        "\n",
        "\n",
        "# Ensure that there is an 'image_link' column in the dataset\n",
        "if 'image_link' not in df.columns:\n",
        "    raise ValueError(\"The dataset must contain an 'image_link' column with image paths or URLs.\")\n",
        "\n",
        "# Initialize a new column for extracted text\n",
        "df['extracted_text'] = None\n",
        "\n",
        "# Iterate over the dataset and extract text for each image\n",
        "for idx, row in df.iterrows():\n",
        "    image_path = row['image_link']\n",
        "    extracted_text = extract_text(image_path)  # Extract text from the image\n",
        "\n",
        "    if extracted_text is not None:\n",
        "        df.at[idx, 'extracted_text'] = extracted_text\n",
        "        success_count += 1\n",
        "    else:\n",
        "        error_count += 1\n",
        "\n",
        "# Save the updated dataset with the extracted text to a new CSV file\n",
        "df.to_csv(output_csv, index=False)\n",
        "\n",
        "# Calculate the total execution time in minutes\n",
        "end_time = time.time()\n",
        "total_time_seconds = end_time - start_time\n",
        "total_time_minutes = total_time_seconds / 60  # Convert to minutes\n",
        "\n",
        "# Print the total time taken in minutes\n",
        "print(f\"Total time taken: {total_time_minutes:.2f} minutes\")\n",
        "\n",
        "# Print the count of successful extractions and errors\n",
        "print(f\"Images successfully extracted: {success_count}\")\n",
        "print(f\"Images with errors: {error_count}\")\n",
        "\n",
        "# Print the path to the output CSV file\n",
        "print(f\"Updated dataset saved to: {output_csv}\")"
      ],
      "metadata": {
        "id": "AuGghGYVuEIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_ocr = pd.read_csv(\"/content/test_ocr_results.csv\")\n",
        "\n",
        "test_ocr[\"image_link\"] = test_ocr[\"Image Path\"]\n",
        "test_ocr[\"extracted_text\"] = test_ocr[\"Extracted Text\"]\n",
        "\n",
        "test_ocr = test_ocr.drop(columns=['Processing Time (seconds)', 'Image Path', 'Extracted Text'])\n",
        "test_ocr"
      ],
      "metadata": {
        "id": "5xxjSORbuGQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv(\"/content/test.csv\")\n",
        "\n",
        "# Define the substring to remove\n",
        "substring_to_remove = 'https://m.media-amazon.com/images/I/'\n",
        "\n",
        "# Remove the substring from the 'links' column\n",
        "test['image_link'] = test['image_link'].str.replace(substring_to_remove, '', regex=False)"
      ],
      "metadata": {
        "id": "8PHFVrAouKqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the two dataframes on the 'image_link' column (left join to preserve all test_df rows)\n",
        "merged_df = pd.merge(test, test_ocr, on='image_link', how='left')"
      ],
      "metadata": {
        "id": "OFH_UHyGuMjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = merged_df"
      ],
      "metadata": {
        "id": "tdqbRGcvuOlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Function to build the pattern for a list of units\n",
        "def build_pattern(units):\n",
        "    # Sort units by length descending to match longer units first\n",
        "    units_sorted = sorted(units, key=lambda x: -len(x))\n",
        "    # Escape units that have special regex characters\n",
        "    units_escaped = [re.escape(u) for u in units_sorted]\n",
        "    # Build the unit pattern, adding word boundaries\n",
        "    units_pattern = '|'.join(units_escaped)\n",
        "    # Build the final pattern\n",
        "    pattern = r\"(\\d+\\.?\\d*)\\s?(\" + units_pattern + r\")\\b\"\n",
        "    return pattern\n",
        "\n",
        "# Define units per entity\n",
        "weight_units = ['milligram', 'mg', 'miligram', 'milligrams', 'miligrammes',\n",
        "                'gram', 'g', 'grams',\n",
        "                'kilogram', 'kg',\n",
        "                'microgram', 'Âµg',\n",
        "                'ounce', 'oz',\n",
        "                'pound', 'lb',\n",
        "                'ton']\n",
        "\n",
        "length_units = ['millimetre', 'mm', 'millimeter',\n",
        "                'centimetre', 'cm', 'centimeter',\n",
        "                'metre', 'meter', r'm(?!m)',  # Negative lookahead to prevent matching 'mm' as 'm'\n",
        "                'foot', 'ft',\n",
        "                'inch', 'in',\n",
        "                'yard', 'yd']\n",
        "\n",
        "voltage_units = ['kilovolt', 'kV', 'kv',\n",
        "                 'millivolt', 'mV', 'mv',\n",
        "                 'volt', 'V', 'v']\n",
        "\n",
        "wattage_units = ['kilowatt', 'kW', 'kw', 'watt', 'W', 'w']\n",
        "\n",
        "volume_units = ['centilitre', 'cl',\n",
        "                'cubic foot', 'ftÂ³',\n",
        "                'cubic inch', 'inÂ³',\n",
        "                'cup',\n",
        "                'decilitre', 'dl',\n",
        "                'fluid ounce', 'fl oz',\n",
        "                'gallon', 'imperial gallon',\n",
        "                'litre', 'liter',\n",
        "                'millilitre', 'ml', 'milliliter',\n",
        "                'microlitre', 'microliter',\n",
        "                'pint', 'quart']\n",
        "\n",
        "# Define the extraction patterns for each entity type\n",
        "patterns = {\n",
        "    'item_weight': build_pattern(weight_units),\n",
        "    'depth': build_pattern(length_units),\n",
        "    'width': build_pattern(length_units),\n",
        "    'height': build_pattern(length_units),\n",
        "    'voltage': build_pattern(voltage_units),\n",
        "    'wattage': build_pattern(wattage_units),\n",
        "    'item_volume': build_pattern(volume_units),\n",
        "    'maximum_weight_recommendation': build_pattern(weight_units)\n",
        "}\n",
        "\n",
        "# Normalize unit names (ensure all keys are in lowercase)\n",
        "unit_mappings = {\n",
        "    # weight units\n",
        "    'mg': 'milligram', 'milligram': 'milligram', 'miligram': 'milligram',\n",
        "    'milligrams': 'milligram', 'miligrammes': 'milligram',\n",
        "    'g': 'gram', 'gram': 'gram', 'grams': 'gram',\n",
        "    'kg': 'kilogram', 'kilogram': 'kilogram',\n",
        "    'Âµg': 'microgram', 'microgram': 'microgram',\n",
        "    'oz': 'ounce', 'ounce': 'ounce',\n",
        "    'lb': 'pound', 'pound': 'pound',\n",
        "    'ton': 'ton',\n",
        "\n",
        "    # length units\n",
        "    'cm': 'centimetre', 'centimetre': 'centimetre', 'centimeter': 'centimetre',\n",
        "    'mm': 'millimetre', 'millimetre': 'millimetre', 'millimeter': 'millimetre',\n",
        "    'm': 'metre', 'metre': 'metre', 'meter': 'metre',\n",
        "    'foot': 'foot', 'ft': 'foot', 'inch': 'inch', 'in': 'inch',\n",
        "    'yard': 'yard', 'yd': 'yard',\n",
        "\n",
        "    # voltage units\n",
        "    'kv': 'kilovolt', 'kilovolt': 'kilovolt',\n",
        "    'mv': 'millivolt', 'millivolt': 'millivolt',\n",
        "    'v': 'volt', 'volt': 'volt',\n",
        "\n",
        "    # wattage units\n",
        "    'kw': 'kilowatt', 'kilowatt': 'kilowatt',\n",
        "    'w': 'watt', 'watt': 'watt',\n",
        "\n",
        "    # volume units\n",
        "    'cl': 'centilitre', 'centilitre': 'centilitre',\n",
        "    'dl': 'decilitre', 'decilitre': 'decilitre',\n",
        "    'ftÂ³': 'cubic foot', 'cubic foot': 'cubic foot',\n",
        "    'inÂ³': 'cubic inch', 'cubic inch': 'cubic inch',\n",
        "    'cup': 'cup',\n",
        "    'fluid ounce': 'fluid ounce', 'fl oz': 'fluid ounce',\n",
        "    'gallon': 'gallon', 'imperial gallon': 'imperial gallon',\n",
        "    'litre': 'litre', 'liter': 'litre',\n",
        "    'ml': 'millilitre', 'millilitre': 'millilitre', 'milliliter': 'millilitre',\n",
        "    'microlitre': 'microlitre', 'microliter': 'microlitre',\n",
        "    'pint': 'pint', 'quart': 'quart'\n",
        "}\n",
        "\n",
        "# Function to extract and normalize quantity and unit from text\n",
        "def extract_quantity(row):\n",
        "    text = row['extracted_text']\n",
        "    entity_name = row['entity_name']\n",
        "\n",
        "    # Skip if text is None\n",
        "    if pd.isna(text):\n",
        "        return ''\n",
        "\n",
        "    pattern = patterns.get(entity_name)\n",
        "    if pattern:\n",
        "        match = re.search(pattern, text, re.IGNORECASE)\n",
        "        if match:\n",
        "            value, unit = match.groups()\n",
        "            value = float(value)\n",
        "            normalized_unit = unit_mappings.get(unit.lower(), unit.lower())\n",
        "            return f\"{value} {normalized_unit}\"\n",
        "\n",
        "    return ''\n",
        "\n",
        "# # Function to check if extracted text matches the entity value\n",
        "# def check_match(row):\n",
        "#     extracted = row['extracted_text']\n",
        "#     entity_value = row['entity_value']\n",
        "\n",
        "#     return extracted == entity_value\n",
        "\n",
        "# Apply the function to the DataFrame\n",
        "df['extracted_text'] = df.apply(extract_quantity, axis=1)\n",
        "# df['match'] = df.apply(check_match, axis=1)"
      ],
      "metadata": {
        "id": "dWzL7-6vuTOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns=[\"image_link\", \"group_id\", \"entity_name\"])"
      ],
      "metadata": {
        "id": "FoYkgLuyuUnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = df['extracted_text']\n",
        "index = df['index']\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    'index': index, # Using index as ID\n",
        "    'prediction': y_pred\n",
        "})\n",
        "\n",
        "submission.to_csv('submission_1.csv', index=False)"
      ],
      "metadata": {
        "id": "mUxOA0FXuaVC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}